{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import datetime\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.truncated_normal(shape, mean, stddev) :shape表示生成张量(kernel)的维度，mean是均值，stddev是标准差\n",
    "#shape [height,width,previous_channel,forward_channel]\n",
    "C1_filter = tf.Variable(tf.truncated_normal([5,5,1,6], stddev = 0.1 ) )\n",
    "C1_biases = tf.Variable(tf.zeros([6]))\n",
    "C3_filter = tf.Variable(tf.truncated_normal([5,5,6,16], stddev = 0.1 ))\n",
    "C3_biases = tf.Variable(tf.constant(1.0, shape=[16]))\n",
    "C5_filter = tf.Variable(tf.truncated_normal([5,5,16,120], stddev = 0.1))\n",
    "C5_biases = tf.Variable(tf.constant(1.0, shape=[120]))\n",
    "\n",
    "OUTPUT_weights = tf.Variable(tf.truncated_normal([84,10], stddev = 0.1))\n",
    "OUTPUT_biases = tf.Variable(tf.constant(1.0, shape=[10]))\n",
    "\n",
    "#使用了 None表示，shape不確定维度時，以任意的維度做輸入。name為Graph抓的參數名稱\n",
    "xs = tf.placeholder(tf.float32, [None,784], name = \"input_image\")\n",
    "#[batch_size,Height,Width,灰階為1]\n",
    "xs2 = tf.reshape(xs,[-1,28,28,1])\n",
    "xs3 = tf.image.per_image_standardization(xs2)\n",
    "\n",
    "#[filter_height, filter_width, in_channels, out_channels]\n",
    "C1 = tf.nn.conv2d(xs3, C1_filter, [1,1,1,1], padding = \"SAME\" )  ##C1: 6@28X28 \n",
    "C1 = tf.nn.relu(C1 + C1_biases)\n",
    "print(\"C1:     \", C1.get_shape().as_list())\n",
    "\n",
    "#用2X2的格子，長跟高都間隔2去跳\n",
    "S2 = tf.nn.max_pool(C1, [1,2,2,1], [1,2,2,1], padding = \"VALID\")  ##S2: 6@14X14\n",
    "print(\"S2:     \", S2.get_shape().as_list())\n",
    "\n",
    "C3 = tf.nn.conv2d(S2, C3_filter, [1,1,1,1], padding = \"VALID\")    ##C3: 16@10X10\n",
    "C3 = tf.nn.relu(C3 + C3_biases)\n",
    "print(\"C3:     \", C3.get_shape().as_list())\n",
    "\n",
    "S4 = tf.nn.max_pool(C3, [1,2,2,1], [1,2,2,1], padding = \"VALID\")   ##S4: 16@5X5\n",
    "print(\"S4:     \", S4.get_shape().as_list())\n",
    "\n",
    "C5 = tf.nn.conv2d(S4, C5_filter, [1,1,1,1], padding = \"VALID\")     ##C5: 120@1X1\n",
    "C5 = tf.nn.relu(C5 + C5_biases)\n",
    "print(\"C5:     \", C5.get_shape().as_list())\n",
    "\n",
    "shape = C5.get_shape().as_list()\n",
    "#判斷C5的shape多少，做後面的reshape\n",
    "#[batch_size,height,width,channel]\n",
    "s1 = shape[1] * shape[2] * shape[3]\n",
    "reshape = tf.reshape(C5,[-1,s1])\n",
    "F6_weights = tf.Variable(tf.truncated_normal([s1,84], stddev = 0.1))\n",
    "F6_biases = tf.Variable(tf.constant(1.0, shape = [84]))\n",
    "print(\"reshape:\", reshape.get_shape().as_list())\n",
    "\n",
    "F6 = tf.nn.relu(tf.matmul(reshape, F6_weights) + F6_biases)\n",
    "print(\"F6:     \", F6.get_shape().as_list())\n",
    "\n",
    "y = tf.matmul(F6, OUTPUT_weights) + OUTPUT_biases\n",
    "print(\"OUTPUT: \", y.get_shape().as_list(), \"\\n\\n\")\n",
    "\n",
    "#保存y，以便在預測的時候使用\n",
    "tf.add_to_collection('pred_network', y)\n",
    "\n",
    "# Define loss and optimizer\n",
    "\n",
    "ys = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=ys))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.06).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "start = datetime.datetime.now()\n",
    "#建立saver\n",
    "saver = tf.train.Saver()\n",
    "for i in range(20000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={xs: batch_xs, ys: batch_ys})\n",
    "    if i % 2000 == 0:\n",
    "        \n",
    "        correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(ys, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        acc_val = sess.run(accuracy, feed_dict={xs: mnist.train.images, ys: mnist.train.labels})\n",
    "        train_accuracy.append(acc_val)\n",
    "        \n",
    "        correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(ys, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        acc_val2 = sess.run(accuracy, feed_dict={xs: mnist.test.images, ys: mnist.test.labels})\n",
    "        test_accuracy.append(acc_val2)\n",
    "        print(\"Train Accuracy=%f, Test Accuracy=%f\" % (acc_val,acc_val2))\n",
    "end = datetime.datetime.now()\n",
    "print(\"總訓練時間: %d s\" % (end-start).seconds)\n",
    "plt.axes([0,0,1,1])\n",
    "plt.plot(train_accuracy, \"-r\" ,  label = \"train_accuracy\")\n",
    "plt.plot(test_accuracy, \"-k\" ,  label = \"test_accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#儲存model\n",
    "saver.save(sess,\"./model/model.ckpt\")\n",
    "\n",
    "\"\"\"\n",
    "model.ckpt.meta文件保存了TensorFlow計算圖的架構，也就是整個類神經網路的架構\n",
    "model.ckpt文件保存了TensorFlow程序中每一個變數的取值\n",
    "checkpoint文件保存了一個目錄下所有的model文件列表\n",
    "\"\"\"\n",
    "\n",
    "sess.close()\n",
    "exit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
